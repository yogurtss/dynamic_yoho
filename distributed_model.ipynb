{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment \n",
    "## Part1: prepare model and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import librosa\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from sklearn import preprocessing\n",
    "np.random.seed(42)\n",
    "# step1: define the entire ia-net-lite model\n",
    "\n",
    "class GLayerNorm(nn.Module):\n",
    "    \"\"\"Global Layer Normalization for TasNet.\"\"\"\n",
    "\n",
    "    def __init__(self, channels, eps=1e-5):\n",
    "        super(GLayerNorm, self).__init__()\n",
    "        self.eps = eps\n",
    "        self.norm_dim = channels\n",
    "        self.gamma = nn.Parameter(torch.Tensor(channels))\n",
    "        self.beta = nn.Parameter(torch.Tensor(channels))\n",
    "        # self.register_parameter('weight', self.gamma)\n",
    "        # self.register_parameter('bias', self.beta)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        nn.init.ones_(self.gamma)\n",
    "        nn.init.zeros_(self.beta)\n",
    "\n",
    "    def forward(self, sample):\n",
    "        \"\"\"Forward function.\n",
    "        Args:\n",
    "            sample: [batch_size, channels, length]\n",
    "        \"\"\"\n",
    "        if sample.dim() != 3:\n",
    "            raise RuntimeError('{} only accept 3-D tensor as input'.format(\n",
    "                self.__name__))\n",
    "        # [N, C, T] -> [N, T, C]\n",
    "        sample = torch.transpose(sample, 1, 2)\n",
    "        # Mean and variance [N, 1, 1]\n",
    "        mean = torch.mean(sample, (1, 2), keepdim=True)\n",
    "        var = torch.mean((sample - mean) ** 2, (1, 2), keepdim=True)\n",
    "        sample = (sample - mean) / torch.sqrt(var + self.eps) * \\\n",
    "                 self.gamma + self.beta\n",
    "        # [N, T, C] -> [N, C, T]\n",
    "        sample = torch.transpose(sample, 1, 2)\n",
    "        return sample\n",
    "\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    def __init__(self, inplanes, planes, kernel_size=7, stride=1, downsample=None, expansion=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        inplanes_ = inplanes * expansion\n",
    "        pad = (kernel_size - 1) // 2\n",
    "        self.conv1 = nn.Conv1d(inplanes, inplanes_, kernel_size=1, bias=False)\n",
    "        self.bn1 = GLayerNorm(inplanes_)\n",
    "        self.conv2 = nn.Conv1d(inplanes_, inplanes_, kernel_size=kernel_size, stride=stride,\n",
    "                               padding=pad, bias=False, groups=inplanes_)\n",
    "        self.bn2 = GLayerNorm(inplanes_)\n",
    "        self.conv3 = nn.Conv1d(inplanes_, planes, kernel_size=1, bias=1)\n",
    "        self.bn3 = GLayerNorm(planes)\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ConvMulti(nn.Module):\n",
    "    def __init__(self, inplanes, planes, stride=4):\n",
    "        super(ConvMulti, self).__init__()\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv_7 = nn.Conv1d(inplanes, planes//2, kernel_size=7, stride=stride,\n",
    "                                padding=3, bias=False, groups=planes//2)\n",
    "        self.bn_7 = GLayerNorm(planes//2)\n",
    "\n",
    "        self.conv_5 = nn.Conv1d(inplanes, planes//2, kernel_size=5, stride=stride,\n",
    "                                padding=2, bias=False, groups=planes//2)\n",
    "        self.bn_5 = GLayerNorm(planes//2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output_7 = self.bn_7(self.conv_7(x))\n",
    "        output_5 = self.bn_5(self.conv_5(x))\n",
    "        return self.relu(torch.cat([output_7, output_5], dim=1))\n",
    "\n",
    "\n",
    "class BottleneckMulti(nn.Module):\n",
    "    def __init__(self, inplanes, planes, kernel_size=7, stride=1, downsample=None, expansion=1):\n",
    "        super(BottleneckMulti, self).__init__()\n",
    "        inplanes_ = inplanes * expansion\n",
    "        pad = (kernel_size - 1) // 2\n",
    "        self.conv1 = nn.Conv1d(inplanes, inplanes_, kernel_size=1, bias=False)\n",
    "        self.bn1 = GLayerNorm(inplanes_)\n",
    "        # self.conv2 = nn.Conv1d(inplanes_, inplanes_, kernel_size=kernel_size, stride=stride,\n",
    "        #                        padding=pad, bias=False, groups=inplanes_)\n",
    "        # self.bn2 = GLayerNorm(inplanes_)\n",
    "        self.conv2 = ConvMulti(inplanes_, inplanes_, stride)\n",
    "        self.conv3 = nn.Conv1d(inplanes_, planes, kernel_size=1, bias=1)\n",
    "        self.bn3 = GLayerNorm(planes)\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        # out = self.bn2(out)\n",
    "        # out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.conv_7 = nn.Conv1d(in_channels, out_channels//2, kernel_size=7, stride=4, padding=3, bias=False)\n",
    "        self.conv_5 = nn.Conv1d(in_channels, out_channels//2, kernel_size=5, stride=4, padding=2, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output_7 = self.conv_7(x)\n",
    "        output_5 = self.conv_5(x)\n",
    "        return torch.cat([output_7, output_5], dim=1)\n",
    "\n",
    "\n",
    "class MobileNetV2(nn.Module):\n",
    "    def __init__(self, block, layers, n_spk=4, num_emed=128, mode='train'):\n",
    "        super(MobileNetV2, self).__init__()\n",
    "        self.mode = mode\n",
    "        self.inplanes = 32\n",
    "        self.n_spk = n_spk\n",
    "        self.num_emed = num_emed\n",
    "        # self.conv1 = nn.Conv1d(1, 32, kernel_size=7, stride=4, padding=3, bias=False)\n",
    "        self.conv1 = Encoder(1, 32)\n",
    "        self.bn1 = GLayerNorm(32)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.layer1 = self._make_layer(block, 16, layers[0], stride=1, expansion=1)\n",
    "        self.layer2 = self._make_layer(block, 24, layers[1], stride=4, expansion=6)\n",
    "        self.layer3 = self._make_layer(block, 32, layers[2], stride=4, expansion=6)\n",
    "        self.layer4 = self._make_layer(block, 64, layers[3], stride=4, expansion=6)\n",
    "        self.layer5 = self._make_layer(block, 96, layers[4], stride=1, expansion=6)\n",
    "        self.layer6 = self._make_layer(block, 160, layers[5], stride=4, expansion=6)\n",
    "        self.layer7 = self._make_layer(block, 320, layers[6], stride=1, expansion=6)\n",
    "        self.conv8 = nn.Conv1d(320, 1280, kernel_size=1, stride=1, bias=False)\n",
    "        self.avgpool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Linear(1280, num_emed*n_spk)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride, expansion):\n",
    "        downsample = nn.Sequential(\n",
    "            nn.Conv1d(self.inplanes, planes,\n",
    "                      kernel_size=1, stride=stride, bias=False),\n",
    "            GLayerNorm(planes),\n",
    "        )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride=stride, downsample=downsample, expansion=expansion))\n",
    "        self.inplanes = planes\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, expansion=expansion))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward_once(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.layer5(x)\n",
    "        x = self.layer6(x)\n",
    "        x = self.layer7(x)\n",
    "\n",
    "        x = self.conv8(x)\n",
    "        x = self.avgpool(x).squeeze(-1)\n",
    "        x = self.fc(x)\n",
    "        features =[]\n",
    "        start = 0\n",
    "        for i in range(self.n_spk):\n",
    "            f = x[:, start:start+self.num_emed]\n",
    "            start += self.num_emed\n",
    "            features.append(f)\n",
    "        return features\n",
    "\n",
    "    def forward(self, input):\n",
    "        if self.mode == \"train\":\n",
    "            features = self.forward_once(input[0])\n",
    "            features_ = self.forward_once(input[1])\n",
    "            return features, features_\n",
    "        else:\n",
    "            return self.forward_once(input)\n",
    "\n",
    "\n",
    "def mobilenet_19(**kwargs):\n",
    "    \"\"\"Constructs a MobileNetV2-19 model.\n",
    "    \"\"\"\n",
    "    n_spk = kwargs[\"n_spk\"] if \"n_spk\" in kwargs else 4\n",
    "    num_emed = kwargs[\"num_emed\"] if \"num_emed\" in kwargs else 128\n",
    "    mode = kwargs[\"mode\"] if \"mode\" in kwargs else 'train'\n",
    "    model = MobileNetV2(BottleneckMulti, [1, 2, 3, 4, 3, 3, 1], n_spk, num_emed, mode)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the distributed ia-net-lite\n",
    "class Part_1(nn.Module):\n",
    "    def __init__(self, backbone, mode=\"train\"):\n",
    "        super(Part_1, self).__init__()\n",
    "        self.mode = mode\n",
    "        self.conv1 = backbone.conv1\n",
    "        self.bn1 = backbone.bn1\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.layer1 = backbone.layer1\n",
    "        self.layer2 = backbone.layer2\n",
    "        self.layer3 = backbone.layer3\n",
    "        self.layer4 = backbone.layer4\n",
    "\n",
    "    def forward_once(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, input):\n",
    "        if self.mode == \"train\":\n",
    "            features = self.forward_once(input[0])\n",
    "            features_ = self.forward_once(input[1])\n",
    "            return features, features_\n",
    "        else:\n",
    "            return self.forward_once(input)\n",
    "\n",
    "\n",
    "class Part_2(nn.Module):\n",
    "    def __init__(self, backbone, mode='train'):\n",
    "        super(Part_2, self).__init__()\n",
    "        self.mode = mode\n",
    "        self.layer5 = backbone.layer5\n",
    "        self.layer6 = backbone.layer6\n",
    "\n",
    "    def forward_once(self, x):\n",
    "        x = self.layer5(x)\n",
    "        x = self.layer6(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, input):\n",
    "        if self.mode == \"train\":\n",
    "            features = self.forward_once(input[0])\n",
    "            features_ = self.forward_once(input[1])\n",
    "            return features, features_\n",
    "        else:\n",
    "            return self.forward_once(input)\n",
    "\n",
    "\n",
    "class Part_3(nn.Module):\n",
    "    def __init__(self, backbone, mode='train'):\n",
    "        super(Part_3, self).__init__()\n",
    "        self.num_emed = backbone.num_emed\n",
    "        self.n_spk = backbone.n_spk\n",
    "        self.mode = mode\n",
    "        self.layer7 = backbone.layer7\n",
    "        self.conv8 = backbone.conv8\n",
    "        self.avgpool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = backbone.fc\n",
    "\n",
    "    def forward_once(self, x):\n",
    "        x = self.layer7(x)\n",
    "        x = self.conv8(x)\n",
    "        x = self.avgpool(x).squeeze(-1)\n",
    "        x = self.fc(x)\n",
    "        features = []\n",
    "        start = 0\n",
    "        for i in range(self.n_spk):\n",
    "            f = x[:, start:start + self.num_emed]\n",
    "            start += self.num_emed\n",
    "            features.append(f)\n",
    "        return features\n",
    "\n",
    "    def forward(self, input):\n",
    "        if self.mode == \"train\":\n",
    "            features = self.forward_once(input[0])\n",
    "            features_ = self.forward_once(input[1])\n",
    "            return features, features_\n",
    "        else:\n",
    "            return self.forward_once(input)\n",
    "\n",
    "\n",
    "def build_part(backbone, mode='train'):\n",
    "    \"\"\"Constructs a MobileNetV2-19 model.\n",
    "    \"\"\"\n",
    "    # backbone = mobilenet_19()\n",
    "    part1 = Part_1(backbone, mode=mode)\n",
    "    part2 = Part_2(backbone, mode=mode)\n",
    "    part3 = Part_3(backbone, mode=mode)\n",
    "    return part1, part2, part3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Part_3(\n",
       "  (layer7): Sequential(\n",
       "    (0): BottleneckMulti(\n",
       "      (conv1): Conv1d(160, 960, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn1): GLayerNorm()\n",
       "      (conv2): ConvMulti(\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv_7): Conv1d(960, 480, kernel_size=(7,), stride=(1,), padding=(3,), groups=480, bias=False)\n",
       "        (bn_7): GLayerNorm()\n",
       "        (conv_5): Conv1d(960, 480, kernel_size=(5,), stride=(1,), padding=(2,), groups=480, bias=False)\n",
       "        (bn_5): GLayerNorm()\n",
       "      )\n",
       "      (conv3): Conv1d(960, 320, kernel_size=(1,), stride=(1,))\n",
       "      (bn3): GLayerNorm()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv1d(160, 320, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (1): GLayerNorm()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (conv8): Conv1d(320, 1280, kernel_size=(1,), stride=(1,), bias=False)\n",
       "  (avgpool): AdaptiveAvgPool1d(output_size=1)\n",
       "  (fc): Linear(in_features=1280, out_features=1024, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the entire model and split model\n",
    "model = mobilenet_19(num_emed=256, n_spk=4, mode='inference')\n",
    "model_path = \"./model_params.pkl\"\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model = model.cuda()\n",
    "model.eval()\n",
    "model_part1, model_part2, model_part3 = build_part(model, mode=\"inference\")\n",
    "model_part1.eval()\n",
    "model_part2.eval()\n",
    "model_part3.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 160000)\n",
      "(1, 160000)\n",
      "(1, 98304)\n",
      "(1, 98304)\n"
     ]
    }
   ],
   "source": [
    "# prepare data\n",
    "def load_data(path_list):\n",
    "    scaler = preprocessing.MaxAbsScaler()\n",
    "    sources = []\n",
    "    mix = np.zeros(160000, dtype=np.float32)\n",
    "    for path in path_list:\n",
    "        data, _ = librosa.load(path, sr=16000, mono=True)\n",
    "        mix += data\n",
    "        data = scaler.fit_transform(data.reshape(-1, 1)).T\n",
    "        sources.append(data)\n",
    "    mix = scaler.fit_transform(mix.reshape(-1, 1)).T\n",
    "    return mix\n",
    "    \n",
    "s1_normal = \"./data/normals/pump/0.wav\"\n",
    "s2_normal = \"./data/normals/slider/0.wav\"\n",
    "s3_normal = \"./data/normals/fan/0.wav\"\n",
    "s4_normal = \"./data/normals/valve/0.wav\"\n",
    "s1_abnormal = \"./data/abnormals/pump/0.wav\"\n",
    "s2_abnormal = \"./data/abnormals/slider/0.wav\"\n",
    "s3_abnormal = \"./data/abnormals/fan/0.wav\"\n",
    "s4_abnormal = \"./data/abnormals/valve/0.wav\"\n",
    "\n",
    "mix_baseline = load_data([s1_normal, s2_normal, s3_normal, s4_normal])\n",
    "mix = load_data([s1_abnormal, s2_normal, s3_normal, s4_abnormal])\n",
    "mix_baseline_short = mix_baseline[:, :98304]\n",
    "mix_short = mix[:, :98304]\n",
    "print(mix_baseline.shape)\n",
    "print(mix.shape)\n",
    "print(mix_baseline_short.shape)\n",
    "print(mix_short.shape)\n",
    "# conver numpy to Tensor\n",
    "mix_baseline_short = torch.Tensor(mix_baseline_short).to(\"cuda:0\")\n",
    "mix_short = torch.Tensor(mix_short).to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 98304])\n",
      "torch.Size([1, 98304])\n",
      "Entire computation time is 0.07651120000082301\n"
     ]
    }
   ],
   "source": [
    "# compute results of entire ia-net-lite\n",
    "print(mix_baseline_short.size())\n",
    "print(mix_short.size())\n",
    "t_start = time.perf_counter()\n",
    "features_baseline = model(mix_baseline_short.unsqueeze(0))\n",
    "t_entire = time.perf_counter() - t_start\n",
    "t_start = time.perf_counter()\n",
    "features = model(mix_short.unsqueeze(0))\n",
    "t_entire = time.perf_counter() - t_start\n",
    "print(\"Entire computation time is {}\".format(t_entire))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dis. computation time is 0.08116300000074261\n"
     ]
    }
   ],
   "source": [
    "# compute results of distributed ia-net-lite\n",
    "t_start = time.perf_counter()\n",
    "features_dis = model_part1(mix_short.unsqueeze(0))\n",
    "features_dis = model_part2(features_dis)\n",
    "features_dis = model_part3(features_dis)\n",
    "t_dis = time.perf_counter() - t_start\n",
    "print(\"Dis. computation time is {}\".format(t_dis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_anomal_score(feature_baseline, feature, n=4):\n",
    "    ans = []\n",
    "    for i in range(n):\n",
    "        d = (feature_baseline[i] - feature[i]).pow(2).sum(1)\n",
    "        ans.append(d.item())\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part2: How to split data \n",
    "To split the data, the FC needs to separate from the other layers\n",
    "\n",
    "conv layers - output - fc-layer - result\n",
    "a, b, c           outa+outb+outc  - output - fc-layer - result\n",
    "\n",
    "\n",
    "input --- 32 inputs -> vnf1 - vnf2 - vnf3 - server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLayers(nn.Module):\n",
    "    def __init__(self, backbone, mode=\"train\"):\n",
    "        super(ConvLayers, self).__init__()\n",
    "        self.mode = mode\n",
    "        self.conv1 = backbone.conv1\n",
    "        self.bn1 = backbone.bn1\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.layer1 = backbone.layer1\n",
    "        self.layer2 = backbone.layer2\n",
    "        self.layer3 = backbone.layer3\n",
    "        self.layer4 = backbone.layer4\n",
    "        self.layer5 = backbone.layer5\n",
    "        self.layer6 = backbone.layer6\n",
    "        self.layer7 = backbone.layer7\n",
    "        self.conv8 = backbone.conv8\n",
    "\n",
    "\n",
    "    def forward_once(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.layer5(x)\n",
    "        x = self.layer6(x)\n",
    "        x = self.layer7(x)\n",
    "        x = self.conv8(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, input):\n",
    "        if self.mode == \"train\":\n",
    "            features = self.forward_once(input[0])\n",
    "            features_ = self.forward_once(input[1])\n",
    "            return features, features_\n",
    "        else:\n",
    "            return self.forward_once(input)\n",
    "\n",
    "class FCLayers(nn.Module):\n",
    "    def __init__(self, backbone, mode='train') -> None:\n",
    "        super(FCLayers, self).__init__()\n",
    "        self.num_emed = backbone.num_emed\n",
    "        self.n_spk = backbone.n_spk\n",
    "        self.mode = mode\n",
    "        self.avgpool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = backbone.fc\n",
    "    \n",
    "    def forward_once(self, x):\n",
    "        x = self.avgpool(x).squeeze(-1)\n",
    "        x = self.fc(x)\n",
    "        features = []\n",
    "        start = 0\n",
    "        for i in range(self.n_spk):\n",
    "            f = x[:, start:start + self.num_emed]\n",
    "            start += self.num_emed\n",
    "            features.append(f)\n",
    "        return features\n",
    "\n",
    "    def forward(self, input):\n",
    "        if self.mode == \"train\":\n",
    "            features = self.forward_once(input[0])\n",
    "            features_ = self.forward_once(input[1])\n",
    "            return features, features_\n",
    "        else:\n",
    "            return self.forward_once(input)\n",
    "\n",
    "conv_layers = ConvLayers(model, mode=\"inference\")\n",
    "fc_layer = FCLayers(model, mode=\"inference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1280, 3])\n",
      "Split computation time: 0.8042284999992262\n"
     ]
    }
   ],
   "source": [
    "## splite the 2s segment to 2 parts along the time domain\n",
    "import math\n",
    "def splite_data(data, n, dim):\n",
    "    t = data.size()[-1]\n",
    "    l = t // n\n",
    "    data_list = torch.split(data, l, dim=dim)\n",
    "    return data_list\n",
    "\n",
    "class Spliter:\n",
    "    def __init__(self, model, input_size, s, n) -> None:\n",
    "        '''\n",
    "        model:\n",
    "        input_size: shape of input data, size should be like [b, c, t] \n",
    "        s: stride size, depends on the model\n",
    "        n: numbero of splited data\n",
    "        '''\n",
    "        assert n <= input_size // s\n",
    "        self.model = model\n",
    "        self.s = s\n",
    "        self.n = n\n",
    "        sub_size = input_size // n\n",
    "        self.size = sub_size\n",
    "\n",
    "    def compute_once(self, x):\n",
    "        b, c, t = x.shape\n",
    "        left = t % self.s\n",
    "        if left != 0:\n",
    "            zeros_pad = torch.zeros([b, c, self.s - left], dtype=torch.float32).cuda()\n",
    "            x = torch.cat([x, zeros_pad], dim=2)\n",
    "        return self.model(x)\n",
    "\n",
    "    def split_and_compute(self, x):\n",
    "        if self.n == 1:\n",
    "            return self.model(x)\n",
    "        if len(x.size()) == 2:\n",
    "            x = x.unsqueeze(0)\n",
    "        split_list = torch.split(x, self.size, dim=2)\n",
    "        ans = []\n",
    "        for sub_input in split_list:\n",
    "            out = self.compute_once(sub_input)\n",
    "            '''\n",
    "            此处可以添加发送的逻辑\n",
    "            '''\n",
    "            ans.append(out)\n",
    "        return ans\n",
    "\n",
    "s = Spliter(conv_layers, 98304, 1024, 32)\n",
    "t_start = time.perf_counter()\n",
    "ans = s.split_and_compute(mix_short)\n",
    "print(ans[0].size())\n",
    "t_split = time.perf_counter() - t_start\n",
    "feature_combine = torch.cat(ans, dim=2)\n",
    "feature_combine = fc_layer(feature_combine)\n",
    "print(\"Split computation time: {}\".format(t_split))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part3 split & or not\n",
    "Let's only split & send into first two parts\n",
    "First we define a combiner\n",
    "32 - idx0, idx1 -> part2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Combiner:\n",
    "    def __init__(self, model, s_prev, s_cur, n = None) -> None:\n",
    "        self.model = model\n",
    "        self.cache = []\n",
    "        self.n = math.floor(s_prev/s_cur) if n is None else n\n",
    "\n",
    "    def combine_and_compute(self, x):\n",
    "        self.cache.append(x)\n",
    "        if len(self.cache) < self.n:\n",
    "            return None\n",
    "        input = torch.cat(self.cache, dim=2)\n",
    "        self.cache = []\n",
    "        return self.model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 12])\n",
      "torch.Size([1, 160, 96])\n"
     ]
    }
   ],
   "source": [
    "s1 = Spliter(model_part1, 98304, 256, 32)\n",
    "ans = s1.split_and_compute(mix_short)\n",
    "print(ans[0].size())\n",
    "s2 = Spliter(model_part2, 12, 4, 1)\n",
    "ans_ = []\n",
    "for x in ans:\n",
    "    out = s2.split_and_compute(x)\n",
    "    ans_.append(out)\n",
    "feature_combine_1 = torch.cat(ans_, dim=2)\n",
    "print(feature_combine_1.size())\n",
    "feature_combine_1 = model_part3(feature_combine_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11.72973918914795, 0.1781705617904663, 0.03114146739244461, 2.6397199630737305]\n",
      "[11.72973918914795, 0.1781705617904663, 0.03114146739244461, 2.6397199630737305]\n",
      "[8.744229316711426, 1.8077257871627808, 2.1615681648254395, 54.81706237792969]\n",
      "[7.211784362792969, 12.4138765335083, 0.17199158668518066, 56.764930725097656]\n"
     ]
    }
   ],
   "source": [
    "# Compare distance\n",
    "distance_entire = calculate_anomal_score(features_baseline, features)\n",
    "distance_distributed = calculate_anomal_score(features_baseline, features_dis)\n",
    "distance_split = calculate_anomal_score(features_baseline, feature_combine)\n",
    "distance_split_1 = calculate_anomal_score(features_baseline, feature_combine_1)\n",
    "print(distance_entire)\n",
    "print(distance_distributed)\n",
    "print(distance_split)\n",
    "print(distance_split_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Part_Conv_3(nn.Module):\n",
    "    def __init__(self, backbone, mode='train'):\n",
    "        super(Part_Conv_3, self).__init__()\n",
    "        self.num_emed = backbone.num_emed\n",
    "        self.n_spk = backbone.n_spk\n",
    "        self.mode = mode\n",
    "        self.layer7 = backbone.layer7\n",
    "        self.conv8 = backbone.conv8\n",
    "\n",
    "    def forward_once(self, x):\n",
    "        x = self.layer7(x)\n",
    "        x = self.conv8(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, input):\n",
    "        if self.mode == \"train\":\n",
    "            features = self.forward_once(input[0])\n",
    "            features_ = self.forward_once(input[1])\n",
    "            return features, features_\n",
    "        else:\n",
    "            return self.forward_once(input)\n",
    "\n",
    "class Part_FC_3(nn.Module):\n",
    "    def __init__(self, backbone, mode='train'):\n",
    "        super(Part_FC_3, self).__init__()\n",
    "        self.num_emed = backbone.num_emed\n",
    "        self.n_spk = backbone.n_spk\n",
    "        self.mode = mode\n",
    "        self.avgpool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = backbone.fc\n",
    "\n",
    "    def forward_once(self, x):\n",
    "        x = self.avgpool(x).squeeze(-1)\n",
    "        x = self.fc(x)\n",
    "        features = []\n",
    "        start = 0\n",
    "        for i in range(self.n_spk):\n",
    "            f = x[:, start:start + self.num_emed]\n",
    "            start += self.num_emed\n",
    "            features.append(f)\n",
    "        return features\n",
    "\n",
    "    def forward(self, input):\n",
    "        if self.mode == \"train\":\n",
    "            features = self.forward_once(input[0])\n",
    "            features_ = self.forward_once(input[1])\n",
    "            return features, features_\n",
    "        else:\n",
    "            return self.forward_once(input)\n",
    "\n",
    "part_3_conv = Part_Conv_3(model, mode=\"inference\")\n",
    "part_3_fc = Part_FC_3(model, mode=\"inference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "16\n",
      "torch.Size([1, 1280, 48])\n",
      "2\n",
      "torch.Size([1, 1280, 96])\n"
     ]
    }
   ],
   "source": [
    "s1 = Spliter(model_part1, 98304, 256, 32)\n",
    "ans = s1.split_and_compute(mix_short)\n",
    "print(len(ans))\n",
    "c2 = Combiner(model_part2, -1, -1, 2)\n",
    "ans_2 = []\n",
    "count = 0\n",
    "for x in ans:\n",
    "    out = c2.combine_and_compute(x)\n",
    "    if out is not None:\n",
    "        count += 1\n",
    "        ans_2.append(out)\n",
    "print(len(ans_2))\n",
    "c3 = Combiner(part_3_conv, -1, -1, 8)\n",
    "ans_3 = []\n",
    "for x in ans_2:\n",
    "    out = c3.combine_and_compute(x)\n",
    "    if out is not None:\n",
    "        ans_3.append(out)\n",
    "print(ans_3[0].size())\n",
    "print(len(ans_3))\n",
    "feature_combine_2 = torch.cat(ans_3, dim=2)\n",
    "print(feature_combine_2.size())\n",
    "feature_combine_2 = part_3_fc(feature_combine_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11.72973918914795, 0.1781705617904663, 0.03114146739244461, 2.6397199630737305]\n",
      "[11.72973918914795, 0.1781705617904663, 0.03114146739244461, 2.6397199630737305]\n",
      "[8.744229316711426, 1.8077257871627808, 2.1615681648254395, 54.81706237792969]\n",
      "[7.211784362792969, 12.4138765335083, 0.17199158668518066, 56.764930725097656]\n",
      "[8.683256149291992, 0.027838263660669327, 1.0062261819839478, 17.375463485717773]\n"
     ]
    }
   ],
   "source": [
    "# Compare distance\n",
    "distance_entire = calculate_anomal_score(features_baseline, features)\n",
    "distance_distributed = calculate_anomal_score(features_baseline, features_dis)\n",
    "distance_split = calculate_anomal_score(features_baseline, feature_combine)\n",
    "distance_split_1 = calculate_anomal_score(features_baseline, feature_combine_1)\n",
    "distance_split_2 = calculate_anomal_score(features_baseline, feature_combine_2)\n",
    "print(distance_entire)\n",
    "print(distance_distributed)\n",
    "print(distance_split)\n",
    "print(distance_split_1)\n",
    "print(distance_split_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 如果不分割fc层，直接对最后的结果处理，sum or mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Part_3_mod(nn.Module):\n",
    "    def __init__(self, backbone, mode='train'):\n",
    "        super(Part_3_mod, self).__init__()\n",
    "        self.num_emed = backbone.num_emed\n",
    "        self.n_spk = backbone.n_spk\n",
    "        self.mode = mode\n",
    "        self.layer7 = backbone.layer7\n",
    "        self.conv8 = backbone.conv8\n",
    "        self.avgpool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = backbone.fc\n",
    "\n",
    "    def forward_once(self, x):\n",
    "        x = self.layer7(x)\n",
    "        x = self.conv8(x)\n",
    "        x = self.avgpool(x).squeeze(-1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, input):\n",
    "        if self.mode == \"train\":\n",
    "            features = self.forward_once(input[0])\n",
    "            features_ = self.forward_once(input[1])\n",
    "            return features, features_\n",
    "        else:\n",
    "            return self.forward_once(input)\n",
    "model_part3_mod = Part_3_mod(model, mode=\"inference\")\n",
    "\n",
    "def align_feature(x, n_spk=4, num_emed=256):\n",
    "    features = []\n",
    "    start = 0\n",
    "    for i in range(n_spk):\n",
    "        f = x[:, start:start + num_emed]\n",
    "        start += num_emed\n",
    "        features.append(f)\n",
    "    return features\n",
    "\n",
    "# spliter -> vnf1 -----------  Combiner2 - vnf2 ---------Combiner3 -vnf3-convlayer - fc-layer\n",
    "# (n1 + n2 + n3) chunk_gap + compute+time\n",
    "#  -------------\n",
    "#  -------------\n",
    "#  -------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 12])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    s1 = Spliter(model_part1, 98304, 256, 32)\n",
    "    ans = s1.split_and_compute(mix_short)\n",
    "    print(ans[0].size())\n",
    "    s2 = Spliter(model_part2, 12, 4, 1)\n",
    "    ans_ = []\n",
    "    features_new = torch.zeros([1, 1024], dtype=torch.float64).cuda()\n",
    "    for x in ans:\n",
    "        out = s2.split_and_compute(x)\n",
    "        out = model_part3_mod(out)\n",
    "        features_new += out\n",
    "    features_new = align_feature(features_new)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6244b90f84277ee72069a18aa3311970dfe35e55809d94bd141ebe6546475e5d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('dev_lukashe': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
